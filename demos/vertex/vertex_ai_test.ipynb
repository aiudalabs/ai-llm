{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:33:46.691519Z",
     "start_time": "2024-07-02T03:33:44.018911Z"
    }
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines\n",
    "\n",
    "PROJECT_ID = \"aiuda-ffc77\"\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=\"us-central1\",\n",
    "    staging_bucket=\"gs://aiuda-docs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:33:49.701805Z",
     "start_time": "2024-07-02T03:33:49.698421Z"
    }
   },
   "outputs": [],
   "source": [
    "model = \"gemini-1.0-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:04.623593Z",
     "start_time": "2024-07-02T03:33:53.017041Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  langchain-core langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 Getting metadata from plugin failed with error: ('Unable to acquire impersonated credentials', '{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"Permission \\'iam.serviceAccounts.getAccessToken\\' denied on resource (or it may not exist).\",\\n    \"status\": \"PERMISSION_DENIED\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\\n        \"reason\": \"IAM_PERMISSION_DENIED\",\\n        \"domain\": \"iam.googleapis.com\",\\n        \"metadata\": {\\n          \"permission\": \"iam.serviceAccounts.getAccessToken\"\\n        }\\n      }\\n    ]\\n  }\\n}\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Getting metadata from plugin failed with error: ('Unable to acquire impersonated credentials', '{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"Permission \\'iam.serviceAccounts.getAccessToken\\' denied on resource (or it may not exist).\",\\n    \"status\": \"PERMISSION_DENIED\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\\n        \"reason\": \"IAM_PERMISSION_DENIED\",\\n        \"domain\": \"iam.googleapis.com\",\\n        \"metadata\": {\\n          \"permission\": \"iam.serviceAccounts.getAccessToken\"\\n        }\\n      }\\n    ]\\n  }\\n}\\n')\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-04-18T02:33:34.754459-05:00\", grpc_status:14, grpc_message:\"Getting metadata from plugin failed with error: (\\'Unable to acquire impersonated credentials\\', \\'{\\\\n  \\\"error\\\": {\\\\n    \\\"code\\\": 403,\\\\n    \\\"message\\\": \\\"Permission \\\\\\'iam.serviceAccounts.getAccessToken\\\\\\' denied on resource (or it may not exist).\\\",\\\\n    \\\"status\\\": \\\"PERMISSION_DENIED\\\",\\\\n    \\\"details\\\": [\\\\n      {\\\\n        \\\"@type\\\": \\\"type.googleapis.com/google.rpc.ErrorInfo\\\",\\\\n        \\\"reason\\\": \\\"IAM_PERMISSION_DENIED\\\",\\\\n        \\\"domain\\\": \\\"iam.googleapis.com\\\",\\\\n        \\\"metadata\\\": {\\\\n          \\\"permission\\\": \\\"iam.serviceAccounts.getAccessToken\\\"\\\\n        }\\\\n      }\\\\n    ]\\\\n  }\\\\n}\\\\n\\')\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m Part\u001b[38;5;241m.\u001b[39mfrom_uri(audio_file_uri, mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio/mpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m contents \u001b[38;5;241m=\u001b[39m [audio_file, prompt]\n\u001b[0;32m---> 21\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:665\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    657\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    658\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:790\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    782\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    783\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    784\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    789\u001b[0m )\n\u001b[0;32m--> 790\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2208\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2208\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/yomap/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 Getting metadata from plugin failed with error: ('Unable to acquire impersonated credentials', '{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"Permission \\'iam.serviceAccounts.getAccessToken\\' denied on resource (or it may not exist).\",\\n    \"status\": \"PERMISSION_DENIED\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\\n        \"reason\": \"IAM_PERMISSION_DENIED\",\\n        \"domain\": \"iam.googleapis.com\",\\n        \"metadata\": {\\n          \"permission\": \"iam.serviceAccounts.getAccessToken\"\\n        }\\n      }\\n    ]\\n  }\\n}\\n')"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "# project_id = \"PROJECT_ID\"\n",
    "\n",
    "# vertexai.init(project=project_id, location=\"us-central1\")\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.5-flash-001\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Can you transcribe this interview, in the format of timecode, speaker, caption.\n",
    "Use speaker A, speaker B, etc. to identify speakers.\n",
    "\"\"\"\n",
    "\n",
    "audio_file_uri = \"gs://cloud-samples-data/generative-ai/audio/pixel.mp3\"\n",
    "audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Traducción al español\n",
      "\n",
      "0:00 Orador A Tus dispositivos están mejorando con el tiempo y por eso, pensamos en ello en todo el portafolio, desde teléfonos hasta relojes, auriculares y tabletas. Nos emociona mucho cómo podemos contar una narrativa conjunta en todo.\n",
      "0:18 Orador B Bienvenidos al podcast de Made by Google, donde conocemos a las personas que trabajan en los productos de Google que te encantan. Aquí está tu presentador, Rasheed Finch. Hoy, hablamos con Aisha Sharif y DeCarlos Love. Ambos son gerentes de producto para varios dispositivos Pixel y trabajan en algo que todos los propietarios de Pixel adoran: las caídas de funciones de Pixel. Este es el podcast de Made by Google. Aisha, ¿qué función en tu teléfono Pixel ha sido más transformadora en tu propia vida?\n",
      "0:54 Orador C Tantas funciones. Soy cantante, así que creo que la transcripción grabada ha sido increíble. Porque antes grababa canciones, solo las improvisaba, las grababa, las escribía, pero ahora con la transcripción, funciona tan bien, incluso descifrando letras que están mezcladas, creo que eso es enorme.\n",
      "1:26 Orador B Increíble. DeCarlos, la misma pregunta para ti, pero para Pixel Watch, por supuesto. Los oyentes de larga duración sabrán que trabajas en Pixel Watch. ¿Cuál ha sido la función más transformadora en tu propia vida en Pixel Watch?\n",
      "1:43 Orador D Trabajo en las experiencias de acondicionamiento físico y por eso, para mí, es definitivamente la capacidad de rastrear mi frecuencia cardíaca, pero específicamente, en torno a los diferentes objetivos de frecuencia cardíaca y las funciones de zona que hemos lanzado. Para mí, ha sido súper útil. Mi experiencia es en fútbol, atletismo, en términos de lo que he hecho antes, y usar las funciones de frecuencia cardíaca para realmente ayudarme a comprender que no debería ir tan fuerte cuando estoy corriendo, ya sabes, de manera tranquila 2 o 3 millas y ayudándome a reducir eso un poco. En realidad ha sido bastante transformador para mí ver cómo cosas como mi frecuencia cardíaca en reposo han cambiado debido a esa función.\n",
      "2:28 Orador B Increíble. Y Aisha, sé que dedicamos mucho tiempo y energía a las caídas de funciones dentro del equipo de Pixel. ¿Por qué son tan importantes para nosotros?\n",
      "2:43 Orador C Entonces, exactamente lo que dijo DeCarlos. Son importantes para esta narrativa de que tus dispositivos están mejorando con el tiempo y por eso, pensamos en ello en todo el portafolio, desde teléfonos hasta relojes, auriculares hasta tabletas hasta plegables, que también es un teléfono, pero incluso hemos incluido, como, Chromecast a nuestras caídas a veces y por eso, nos entusiasma mucho cómo podemos contar una narrativa conjunta en todo. La otra parte es que, con nuestro Pixel 8 y 8 Pro, y todavía estoy muy emocionada con esto, tenemos 7 años de actualizaciones del sistema operativo, actualizaciones de seguridad y caídas de funciones. Y por eso, las caídas de funciones simplemente se combinan muy bien con esta narrativa de cómo tus dispositivos están mejorando con el tiempo y seguirán mejorando con el tiempo.\n",
      "3:33 Orador B Sí, todavía estaremos hablando de Pixel 8 y Pixel 8 Pro en 2030, con esos 7 años de actualizaciones de software y te prometo que tendremos un episodio sobre eso en breve. Ahora, la caída de funciones de marzo está a la vuelta de la esquina, pero solo quería mirar hacia atrás a la última, la primera de enero. Aisha, ¿podrías contarnos algunos de los aspectos más destacados de la de enero que se acaba de lanzar?\n",
      "3:58 Orador C Entonces, fue una de las pocas veces que hicimos una caída de software con hardware también. Por lo tanto, fue realmente emocionante sacar ese nuevo color menta en Pixel 8 y 8 Pro. También lanzamos el sensor de temperatura corporal en los EE. UU., por lo que ahora puedes, en realidad, con solo un escaneo de tu frente, obtener tu temperatura corporal, lo cual es enorme. Y luego, una gran cantidad de mejoras de IA se incorporaron a la búsqueda circular para Pixel 8 y 8 Pro, por lo que puedes buscar desde cualquier lugar. Uno de mis favoritos, el emoji de foto. Entonces, ahora, puedes usar fotos que tienes en tu álbum y reaccionar a los mensajes con ellas. Lo más aleatorio, estaba organizando una fiesta de helado de donas y literalmente tenía una foto de un sándwich de helado de donas que usé para reaccionar a los mensajes. Me encantan esas pequeñas reacciones aleatorias aleatorias que puedes publicar.\n",
      "5:00 Orador B Increíble. Y eso fue hace solo 2 meses. Ahora, ya estamos en la caída de funciones de marzo. Hay una para teléfonos Pixel, y luego una para Pixel Watches también. Empecemos ahora con el reloj, DeCarlos. ¿Qué hay de nuevo en marzo?\n",
      "5:19 Orador D La gran noticia para nosotros es que no solo vamos a asegurarnos de que todos tus relojes mejoren con el tiempo, sino que, específicamente, traigamos cosas a los relojes de generación anterior. Entonces, tuvimos algunas funciones que se lanzaron en el Pixel Watch 2 y en esta caída de funciones, estamos trayendo esas funciones al Pixel Watch 1. Algunas de las cosas específicamente están viendo nuestras funciones de ritmo. Lo que mencioné anteriormente sobre nuestras funciones de frecuencia cardíaca también está llegando al Pixel Watch 1. Eso te permite configurar esos diferentes ajustes para apuntar a un ritmo que deseas mantener y obtener esas notificaciones mientras haces ejercicio si estás por delante o por encima de ese ritmo y similar con las zonas de frecuencia cardíaca también. También estamos trayendo el reconocimiento de actividad al Pixel Watch 1 y los usuarios, además de la pausa automática, podrán aprovechar el reconocimiento de actividad para que puedan comenzar sus entrenamientos en caso de que se olviden de iniciarlo por su cuenta, así como recibirán una notificación para ayudarlos a detener sus entrenamientos en caso de que se olviden de finalizar el entrenamiento cuando realmente lo hayan terminado. Fuera de los entrenamientos, otra función que llega en esta caída de funciones es realmente alrededor de la aplicación FitBit relajar. Algo que la gente disfruta del Pixel Watch 2, también lo estamos trayendo allí para que la gente pueda saltar, ya sabes, tomarse un momento relajante y trabajar con ejercicios de respiración directamente en su muñeca.\n",
      "6:42 Orador B Vayamos a la caída de funciones de marzo en el lado del teléfono ahora. Aisha, ¿qué hay de nuevo para los usuarios de teléfonos Pixel?\n",
      "6:51 Orador C Entonces, voy a enviar el sentimiento que DeCarlos compartió con marzo realmente girando en torno a que los dispositivos están hechos para durar. Entonces, Pixel Watch 1 obtiene funciones de Pixel Watch 2, también lo estamos viendo en el lado del teléfono. Entonces, Circle to Search se expandirá a Pixel 7 y 7 Pro. También estamos viendo que el HDR de 10 bits se mueve más allá de la cámara, pero estará disponible en Instagram para que puedas tomar reels de muy alta calidad. También tenemos el uso compartido parcial de pantalla, por lo que, en lugar de tener que compartir toda la pantalla de tu teléfono o tableta, cuando estás en una reunión o tal vez estás transmitiendo, ahora puedes compartir solo una aplicación específica, lo cual es enorme para la privacidad.\n",
      "7:37 Orador B Esas son actualizaciones increíbles en la caída de funciones de marzo. ¿Podrías contarnos un poco más sobre si hay alguna noticia, tal vez, para el resto del portafolio también?\n",
      "7:49 Orador C Sí, entonces nuestro uso compartido de pantalla está llegando a la tableta, también estamos viendo que Docs Markup llega a la tableta. Entonces, en realidad puedes, directamente, como suena, marcar documentos, eh, pero dibujar en ellos, tomar notas en ellos y puedes hacer eso en tu teléfono también. Y luego, otra que es increíble, la conexión Bluetooth está mejorando aún más. Entonces, si previamente conectaste, tal vez, auriculares a un teléfono, ahora, acabas de comprar una tableta. Mostrará que esos estaban asociados con tu cuenta y puedes conectar esos dispositivos mucho más fácilmente también.\n",
      "8:29 Orador B Hay una parte de esta conversación que más espero, que es hacer una pregunta de la comunidad de súper fanáticos de Pixel. Están teniendo la oportunidad cada episodio de hacer una pregunta y la pregunta de hoy proviene de Casey Carpenter y están preguntando, ¿qué impulsa tu elección de nuevo software en las versiones? Lo cual es bueno. Entonces, mencionaste ahora, uh, y DeCarlos, comenzaremos contigo, mencionaste un conjunto de funciones que llegarán al Pixel Watch de primera generación, como, ¿cómo decides cuáles cortar esta vez, cuáles podrían venir la próxima vez? ¿Cómo funciona eso?\n",
      "9:13 Orador D Para nosotros, realmente pensamos en el principio fundamental de que queremos asegurarnos de que estos dispositivos puedan seguir mejorando. Y sabemos que ha habido mejoras desde Pixel Watch 2 y por eso, en este caso, se trata de asegurarnos de que también traigamos esas funciones al Pixel Watch 1. Obviamente, nos gustaría pensar en si realmente puede suceder. A veces, puede haber nuevos sensores o cosas como esa en una nueva generación que simplemente hacen que algunas funciones no sean posibles para una generación anterior, pero en el caso de que podamos devolverla, siempre nos esforzamos por hacerlo. Especialmente cuando sabemos que tenemos una buena recepción de esas funciones y usuarios que nos están dando retroalimentación sobre su utilidad. ¿Cuáles son las cosas que los usuarios realmente valoran y realmente se inclinan hacia eso para ayudar a moldear cómo pensamos en lo que viene después?\n",
      "10:05 Orador B Aisha, DeCarlos mencionó la retroalimentación del usuario como parte de la decisión de lo que viene en una caída de funciones. ¿Qué tan importante es eso para tomar todas las decisiones?\n",
      "10:20 Orador C Creo que la retroalimentación del usuario es enorme para todo lo que hacemos en todos los dispositivos. Entonces, en nuestras caídas, siempre estamos pensando en qué mejoras podemos brindar a las personas en función de la retroalimentación del usuario, pero en función de lo que estamos escuchando. Y por eso, las caídas de funciones son una forma realmente genial de seguir mejorando las funciones que ya se han lanzado y agregar mejoras en la parte superior de ellas. También es una forma para nosotros de introducir cosas completamente nuevas o, como mencionó DeCarlos, tomar cosas que estaban en dispositivos más nuevos y llevarlas de vuelta a los dispositivos más antiguos.\n",
      "10:55 Orador B Ahora, estoy seguro de que mucha gente que escucha se pregunta cuándo pueden poner sus manos en estas nuevas funciones. ¿Cuándo se lanzará realmente la caída de funciones de marzo en sus dispositivos? ¿Algún pensamiento ahí?\n",
      "11:09 Orador C Entonces, la caída de funciones de marzo, todas estas funciones comenzarán a implementarse hoy, 4 de marzo.\n",
      "11:16 Orador B Ahora, hemos tenido muchas, muchas, muchas caídas de funciones a lo largo de los años y me pregunto, ¿hay alguna función en particular que te destaque que hayamos lanzado en una caída de funciones, tal vez, Aisha, puedo comenzar contigo?\n",
      "11:33 Orador C Creo que todas las funciones de llamadas han sido increíblemente útiles para mí. Entonces, un par de mis favoritos, la pantalla de llamada, tuvimos una mejora en diciembre donde ahora obtienes fichas contextuales. Entonces, si alguien está como, dejando un paquete y estás en medio de una reunión, puedes responder a eso. Además, Direct My Call está disponible para números que no son gratuitos, por lo que si estás llamando a la oficina de un médico que comienza con solo tu código de área local, ahora puedes usar Direct My Call en eso, lo cual es un gran ahorro de tiempo también y Clear Calling, me encanta esa función, especialmente cuando intento hablar con mi mamá y ella está hablando con un millón de personas a su alrededor mientras intentamos tener una conversación. Entonces, todas las funciones son increíblemente, increíblemente útiles.\n",
      "12:22 Orador B Eso es increíble. Son elementos básicos de la familia Pixel ahora mismo y todos llegaron a través de una caída de funciones. DeCarlos, por supuesto, Pixel Watch también ha tenido varias caídas de funciones. ¿Algún favorito en eso para ti?\n",
      "12:37 Orador D Sí, tengo un par fuera de las cosas que se lanzan ahora mismo. Creo que una fue cuando lanzamos la función SpO2 en una caída de funciones. Esa fue una de las cosas que escuchamos y sabíamos desde el lanzamiento original de Pixel Watch 1 que la gente estaba emocionada y ansiosa. Entonces, mide tu saturación de oxígeno, puedes usar tu reloj mientras duermes y durante la noche, mediremos esa saturación de oxígeno SpO2 mientras duermes. Entonces, ese fue uno emocionante y recibimos mucha buena retroalimentación por poder lanzarlo y llevarlo al Pixel Watch 1 inicialmente. Entonces, eso fue especial. Oh, en realidad, una de las cosas que está sucediendo en esta última caída de funciones con la aplicación Relax, simplemente me encanta la atención en el diseño en torno a las animaciones de respiración y, por lo tanto, algo que la gente definitivamente debería revisar es, ya sabes, que el equipo que dedicó mucho trabajo para pensar en el ritmo al que ocurre esa animación. Es algo que puedes mirar y simplemente perder el tiempo simplemente mirando y viendo cómo ocurren esas hápticas en esa animación.\n",
      "13:49 Orador B Increíble. Siempre son las pequeñas cosas las que lo hacen extra especial, ¿verdad? Absolutamente. Eso es perfecto. Aisha, DeCarlos, muchas gracias por hacer que la Navidad llegue antes de tiempo una vez más y todos estamos ansiosos por la caída de funciones en marzo.\n",
      "14:02 Orador C Gracias.\n",
      "14:04 Orador D Gracias.\n",
      "14:05 Orador B Gracias por escuchar el podcast de Made by Google. No te pierdas los nuevos episodios. Suscríbete ahora, dondequiera que obtengas tus podcasts para ser el primero en escuchar. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content([response.text, \"Translate to Spanish\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:07.043311Z",
     "start_time": "2024-07-02T03:34:06.537083Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "safety_settings = {\n",
    "    # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:11.035870Z",
     "start_time": "2024-07-02T03:34:11.029313Z"
    }
   },
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    # temperature (float): The sampling temperature controls the degree of\n",
    "    # randomness in token selection.\n",
    "    \"temperature\": 0.28,\n",
    "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
    "    # text output from one prompt.\n",
    "    \"max_output_tokens\": 1000,\n",
    "    # top_p (float): Tokens are selected from most probable to least until\n",
    "    # the sum of their probabilities equals the top-p value.\n",
    "    \"top_p\": 0.95,\n",
    "    # top_k (int): The next token is selected from among the top-k most\n",
    "    # probable tokens.\n",
    "    \"top_k\": 40,\n",
    "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
    "    # settings to use for generating content.\n",
    "    # \"safety_settings\": safety_settings,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:15.453212Z",
     "start_time": "2024-07-02T03:34:15.446529Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_exchange_rate(\n",
    "    currency_from: str = \"USD\",\n",
    "    currency_to: str = \"EUR\",\n",
    "    currency_date: str = \"latest\",\n",
    "):\n",
    "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\n",
    "\n",
    "    Uses the Frankfurter API (https://api.frankfurter.app/) to obtain\n",
    "    exchange rate data.\n",
    "\n",
    "    Args:\n",
    "        currency_from: The base currency (3-letter currency code).\n",
    "            Defaults to \"USD\" (US Dollar).\n",
    "        currency_to: The target currency (3-letter currency code).\n",
    "            Defaults to \"EUR\" (Euro).\n",
    "        currency_date: The date for which to retrieve the exchange rate.\n",
    "            Defaults to \"latest\" for the most recent exchange rate data.\n",
    "            Can be specified in YYYY-MM-DD format for historical rates.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the exchange rate information.\n",
    "            Example: {\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2023-11-24\",\n",
    "                \"rates\": {\"EUR\": 0.95534}}\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"https://api.frankfurter.app/{currency_date}\",\n",
    "        params={\"from\": currency_from, \"to\": currency_to},\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:17.650348Z",
     "start_time": "2024-07-02T03:34:16.836239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 1.0, 'base': 'USD', 'date': '2024-07-01', 'rates': {'SEK': 10.5793}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "\n",
    "get_exchange_rate(currency_from=\"USD\", currency_to=\"SEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:20.385242Z",
     "start_time": "2024-07-02T03:34:20.380144Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=model,  # Required.\n",
    "    tools=[get_exchange_rate],  # Optional.\n",
    "    model_kwargs=model_kwargs,  # Optional.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:28.086070Z",
     "start_time": "2024-07-02T03:34:24.205197Z"
    }
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=\"What is the exchange rate from US dollars to Brasilian Real currency?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:34:28.098484Z",
     "start_time": "2024-07-02T03:34:28.089592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the exchange rate from US dollars to Brasilian Real currency?',\n",
       " 'output': 'The exchange rate from US dollars to Brazilian Real as of today, 2024-07-01, is 1 USD = 5.5855 BRL. \\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy de App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T03:38:28.527554Z",
     "start_time": "2024-07-02T03:34:37.705759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket aiuda-docs\n",
      "Writing to gs://aiuda-docs/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://aiuda-docs/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://aiuda-docs/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352/operations/4227073311978291200\n",
      "ReasoningEngine created. Resource name: projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352\n",
      "To use this ReasoningEngine in another session:\n",
      "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x777ec75adb90> \n",
       "resource name: projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISPLAY_NAME = \"Demo Langchain Application\"\n",
    "\n",
    "remote_app = reasoning_engines.ReasoningEngine.create(\n",
    "    reasoning_engines.LangchainAgent(\n",
    "        model=model,\n",
    "        tools=[get_exchange_rate],\n",
    "        model_kwargs=model_kwargs,\n",
    "    ),\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[reasoningengine,langchain]\",\n",
    "    ],\n",
    "    display_name=DISPLAY_NAME,\n",
    ")\n",
    "remote_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:44:59.972480Z",
     "start_time": "2024-07-02T04:44:59.967100Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install google-cloud-aiplatform[reasoningengine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:45:56.713683Z",
     "start_time": "2024-07-02T04:45:56.709885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_app.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:46:43.225937Z",
     "start_time": "2024-07-02T04:46:38.270436Z"
    }
   },
   "outputs": [],
   "source": [
    "response = remote_app.query(\n",
    "    input=\"What is the exchange rate from US dollars to Swedish currency?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:47:12.590141Z",
     "start_time": "2024-07-02T04:47:12.584072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The exchange rate from US dollars to Swedish krona (SEK) is 1 USD = 10.5793 SEK as of July 1, 2024.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage the deployed application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:48:01.977881Z",
     "start_time": "2024-07-02T04:48:01.274360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x777ec7382750> \n",
       " resource name: projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352,\n",
       " <vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x777ec73cd110> \n",
       " resource name: projects/286295157330/locations/us-central1/reasoningEngines/5808552803773186048]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_engines.ReasoningEngine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T04:49:09.663675Z",
     "start_time": "2024-07-02T04:49:08.979071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x777ec7383790> \n",
       " resource name: projects/286295157330/locations/us-central1/reasoningEngines/5870899511114596352]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_engines.ReasoningEngine.list(\n",
    "    filter='display_name=\"Demo Langchain Application\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yomap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
